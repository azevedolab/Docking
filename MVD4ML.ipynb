{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MVD4ML: Molegro Virtual Docker (MVD) for Machine Learning Modeling**\n",
        "\n",
        "This Jupyter Notebook reads a CSV (comma-separated value) file with energy terms and ligand descriptors determined using Molegro Virtual Docker (MVD) ([Thomsen & Christensen, 2006](https://doi.org/10.1021/jm051197e); [Bitencourt-Ferreira & de Azevedo, 2019](https://doi.org/10.1007/978-1-4939-9752-7_10)) and adds binding affinity data calculated by the program SAnDReS 2.0 ([de Azevedo et al., 2024](https://doi.org/10.1002/jcc.27449)). It needs two input CSV files created with SAnDReS 2.0: one with PDB access codes for the structures in the test set and another with ligand data. All ligands in the CSV file generated with the program MVD should be in the input file obtained using SAnDReS 2.0 (with ligand data) ([de Azevedo et al., 2024](https://doi.org/10.1002/jcc.27449)). MVD4ML will merge all files and output two new CSV files with ligand information for structures in the training and test sets. We may employ these files to build regression models using the Jupyter Notebook [SKReg4Model (Scikit-Learn Regressors for Modeling)](https://colab.research.google.com/drive/13khGiZAgJeexwNjNDi1fSluQfcRyBCDg).\n",
        "<br> </br>\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=1P9cUrTTjl5wAj-Q_jirIQ8opRoQ5c9ja&export=view&authuser=0\" width=600 alt=\"PDB: 2A4L\">\n",
        "<br><i>Structure of a protein-ligand complex ([de Azevedo et al., 1997](https://doi.org/10.1111/j.1432-1033.1997.0518a.x)) with an inhibitor bound to the macromolecule (PDB access code: [2A4L](https://www.rcsb.org/structure/2A4L)). MVD ([Thomsen & Christensen, 2006](https://doi.org/10.1021/jm051197e)) generated this figure.</i></br>\n",
        "<br></br>\n",
        "**References**\n",
        "<br></br>\n",
        "Bitencourt-Ferreira G, de Azevedo WF Jr. Molegro Virtual Docker for Docking. Methods Mol Biol. 2019;2053:149-167. PMID: 31452104. [DOI: 10.1007/978-1-4939-9752-7_10](https://doi.org/10.1007/978-1-4939-9752-7_10) [PubMed](https://pubmed.ncbi.nlm.nih.gov/31452104/)\n",
        "<br></br>\n",
        "De Azevedo WF, Leclerc S, Meijer L, Havlicek L, Strnad M, Kim SH. Inhibition of cyclin-dependent kinases by purine analogues: crystal structure of human cdk2 complexed with roscovitine. Eur J Biochem. 1997; 243(1-2): 518-26.\n",
        "PMID: 9030780.\n",
        "[DOI: 10.1111/j.1432-1033.1997.0518a.x](https://doi.org/10.1111/j.1432-1033.1997.0518a.x) [PubMed](https://pubmed.ncbi.nlm.nih.gov/9030780/)\n",
        "<br></br>\n",
        "De Azevedo WF Jr, Quiroga R, Villarreal MA, da Silveira NJF, Bitencourt-Ferreira G, da Silva AD, Veit-Acosta M, Oliveira PR, Tutone M, Biziukova N, Poroikov V, Tarasova O, Baud S. SAnDReS 2.0: Development of machine-learning models to explore the scoring function space. J Comput Chem. 2024; 45(27): 2333-2346. PMID: 38900052. [DOI: 10.1002/jcc.27449](https://doi.org/10.1002/jcc.27449) [PubMed](https://pubmed.ncbi.nlm.nih.gov/38900052/)\n",
        "<br></br>\n",
        "Thomsen R, Christensen MH. MolDock: a new technique for high-accuracy molecular docking. J Med Chem. 2006; 49(11): 3315-21. [DOI: 10.1021/jm051197e](https://doi.org/10.1021/jm051197e) [PubMed](https://pubmed.ncbi.nlm.nih.gov/16722650/)\n",
        "<br></br>\n",
        "\n",
        "It follows the complete Python code."
      ],
      "metadata": {
        "id": "Tkak54xM0ad2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUP6rIXB0QhP",
        "outputId": "d4c01bc4-517e-4c91-eeb0-f3a652842089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Downloading cdk2_cyclin_a_ki_sandres.csv...done!\n",
            "Downloading cdk2_cyclin_a_ki_mvd.csv...done!\n",
            "Downloading cdk2_cyclin_a_ki_pdb_test_set.csv...done!\n",
            "\n",
            "File /content/cdk2_cyclin_a_ki_sandres_training_set.csv has 106 instances.\n",
            "File /content/cdk2_cyclin_a_ki_sandres_test_set.csv has 45 instances.\n",
            "\n",
            "Number of instances written to file /content/cdk2_cyclin_a_ki_mvd_Training_Set.csv : 106\n",
            "\n",
            "Number of instances written to file /content/cdk2_cyclin_a_ki_mvd_Test_Set.csv : 45\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "#\n",
        "################################################################################\n",
        "# Dr. Walter F. de Azevedo, Jr.                                                #\n",
        "# [Scopus](https://www.scopus.com/authid/detail.uri?authorId=7006435557)       #\n",
        "# [GitHub](https://github.com/azevedolab)                                      #\n",
        "# July 20, 2024                                                                #\n",
        "################################################################################\n",
        "#\n",
        "################################################################################\n",
        "# Define merge_san_mvd() function                                              #\n",
        "################################################################################\n",
        "def merge_san_mvd(san_in,mvd_in):\n",
        "    \"\"\"Function to merge a SAnDReS-generated file\n",
        "    ([de Azevedo et al., 2024](https://doi.org/10.1002/jcc.27449)) with\n",
        "    an MVD-generated file\n",
        "    ([Thomsen & Christensen, 2006](https://doi.org/10.1021/jm051197e)).\n",
        "    It adds experimental affinity data in an SAnDReS-generated file to an\n",
        "    MVD-generate file.\n",
        "    <br></br>\n",
        "    **References**\n",
        "    <br></br>\n",
        "    De Azevedo WF Jr, Quiroga R, Villarreal MA, da Silveira NJF,\n",
        "    Bitencourt-Ferreira G, da Silva AD, Veit-Acosta M, Oliveira PR, Tutone M,\n",
        "    Biziukova N, Poroikov V, Tarasova O, Baud S. SAnDReS 2.0: Development of\n",
        "    machine-learning models to explore the scoring function space. J Comput\n",
        "    Chem. 2024; 45(27): 2333-2346. PMID: 38900052.\n",
        "    [DOI: 10.1002/jcc.27449](https://doi.org/10.1002/jcc.27449)\n",
        "    [PubMed](https://pubmed.ncbi.nlm.nih.gov/38900052/)\n",
        "    <br></br>\n",
        "    Thomsen R, Christensen MH. MolDock: a new technique for high-accuracy\n",
        "    molecular docking. J Med Chem. 2006; 49(11): 3315-21.\n",
        "    [DOI: 10.1021/jm051197e](https://doi.org/10.1021/jm051197e)\n",
        "    [PubMed](https://pubmed.ncbi.nlm.nih.gov/16722650/)\n",
        "    <br></br>\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ############################################################################\n",
        "    # Import section\n",
        "    ############################################################################\n",
        "    import csv\n",
        "    import sys\n",
        "\n",
        "    ############################################################################\n",
        "    # SAnDReS-generated file\n",
        "    ############################################################################\n",
        "    # Define columns of the SAnDReS CSV file\n",
        "    ref_col_san1 = 9\n",
        "    ref_col_san2 = 11\n",
        "    ref_col_san3 = 13\n",
        "    ref_col_san4 = 16\n",
        "    ref_col_san5 = 17\n",
        "    ref_col_san6 = 18\n",
        "    ref_col_san7 = 24\n",
        "\n",
        "    # Try to open san_in\n",
        "    try:\n",
        "        fo_san = open(san_in,\"r\")\n",
        "        csv_san = csv.reader(fo_san)\n",
        "    except IOError:\n",
        "        msg_out = \"\\nIOError! I can't find file \"+san_in\n",
        "        sys.exit(msg_out)\n",
        "\n",
        "    # Looping through csv_san\n",
        "    for line1 in csv_san:\n",
        "        header1 = str(line1[:ref_col_san1])+\",\"\n",
        "        header1 += str(line1[ref_col_san2:ref_col_san3])+\",\"\n",
        "        header1 += str(line1[ref_col_san4:ref_col_san5])+\",\"\n",
        "        header1 += str(line1[ref_col_san6:ref_col_san7])\n",
        "        header1 = header1.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").\\\n",
        "                    replace(\" \",\"\").replace(\"AverageQ\",\"Average Q\")\n",
        "\n",
        "        break\n",
        "\n",
        "    ############################################################################\n",
        "    # MVD-generated file\n",
        "    ############################################################################\n",
        "    # Define mvd_out string\n",
        "    if \"training\" in san_in:\n",
        "        mvd_out = mvd_in.replace(\".csv\",\"_Training_Set.csv\")\n",
        "    elif \"test\" in san_in:\n",
        "        mvd_out = mvd_in.replace(\".csv\",\"_Test_Set.csv\")\n",
        "    else:\n",
        "        mvd_out = mvd_in.replace(\".csv\",\"_binding.csv\")\n",
        "\n",
        "    # Try to open mvd_in\n",
        "    try:\n",
        "        fo_mvd = open(mvd_in,\"r\")\n",
        "        csv_mvd = csv.reader(fo_mvd)\n",
        "    except IOError:\n",
        "        msg_out = \"\\nIOError! I can't find file \"+mvd_in\n",
        "        sys.exit(msg_out)\n",
        "\n",
        "    # Looping through csv_mvd\n",
        "    for line2 in csv_mvd:\n",
        "        i = 0\n",
        "        for aux in line2:\n",
        "            if aux.strip() == \"SMILES\":\n",
        "                i_SMILES = i\n",
        "            elif aux.strip() == \"Complex\":\n",
        "                i_Complex = i\n",
        "            elif aux.strip() == \"Filename\":\n",
        "                i_Filename = i\n",
        "            elif aux.strip() == \"Ligand\":\n",
        "                i_Ligand = i\n",
        "            elif aux.strip() == \"Path\":\n",
        "                i_Path = i\n",
        "            elif aux.strip() == \"RMSD\":\n",
        "                i_RMSD = i\n",
        "            elif aux.strip() == \"SimilarityScore\":\n",
        "                i_S = i\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        # Clean header2\n",
        "        # Warning!\n",
        "        # This code keeps the labels used in MVD except for\n",
        "        # \"E-Intra (tors, ligand atoms)\".\n",
        "        # We replaced it for \"E-Intra(tors-ligand atoms)\".\n",
        "        header2 = str(line2[i_SMILES+1:i_Complex])+\",\"\n",
        "        header2 += str(line2[i_Complex+1:i_Filename])+\",\"\n",
        "        header2 += str(line2[i_Filename+1:i_Ligand])+\",\"\n",
        "        header2 += str(line2[i_Ligand+1:i_Path])+\",\"\n",
        "        header2 += str(line2[i_Path+1:i_RMSD])+\",\"\n",
        "        header2 += str(line2[i_RMSD+1:i_S])+\",\"\n",
        "        header2 += str(line2[i_S+1:])\n",
        "        header2 = header2.replace(\"[\",\"\").replace(\" \",\"\").\\\n",
        "        replace(\"]\",\"\").replace(\"'\",\"\").\\\n",
        "        replace(\"Cofactor(VdW)\",\"Cofactor (VdW)\").\\\n",
        "        replace(\"Cofactor(elec)\",\"Cofactor (elec)\").\\\n",
        "        replace(\"Cofactor(hbond)\",\"Cofactor (hbond)\").\\\n",
        "        replace(\"E-Inter(cofactor-ligand)\",\"E-Inter (cofactor - ligand)\").\\\n",
        "        replace(\"E-Inter(protein-ligand)\",\"E-Inter (protein - ligand)\").\\\n",
        "        replace(\"E-Inter(water-ligand)\",\"E-Inter (water - ligand)\").\\\n",
        "        replace(\"E-Intertotal\",\"E-Inter total\").\\\n",
        "        replace(\"E-Intra(clash)\",\"E-Intra (clash)\").\\\n",
        "        replace(\"E-Intra(elec)\",\"E-Intra (elec)\").\\\n",
        "        replace(\"E-Intra(hbond)\",\"E-Intra (hbond)\").\\\n",
        "        replace(\"E-Intra(sp2-sp2)\",\"E-Intra (sp2-sp2)\").\\\n",
        "        replace(\"E-Intra(steric)\",\"E-Intra (steric)\").\\\n",
        "        replace(\"E-Intra(tors)\",\"E-Intra (tors)\").\\\n",
        "        replace(\"E-Intra(tors,ligandatoms)\",\"E-Intra (tors-ligand atoms)\").\\\n",
        "        replace(\"E-Intra(vdw)\",\"E-Intra (vdw)\").\\\n",
        "        replace(\"E-SoftConstraintPenalty\",\"E-Soft Constraint Penalty\").\\\n",
        "        replace(\"VdW(LJ12-6)\",\"VdW (LJ12-6)\")\n",
        "\n",
        "        break\n",
        "\n",
        "    # Close fo_mvd to re-open it into the next loop\n",
        "    fo_mvd.close()\n",
        "\n",
        "    ############################################################################\n",
        "    # Merge data\n",
        "    ############################################################################\n",
        "    # New header\n",
        "    data_out = header1+\",\"+header2+\"\\n\"\n",
        "\n",
        "    # Looping through csv_san\n",
        "    count_instances = 0\n",
        "    for line1 in csv_san:\n",
        "        line_out1 = str(line1[:ref_col_san1])+\",\"\n",
        "        line_out1 += str(line1[ref_col_san2:ref_col_san3])+\",\"\n",
        "        line_out1 += str(line1[ref_col_san4:ref_col_san5])+\",\"\n",
        "        line_out1 += str(line1[ref_col_san6:ref_col_san7])\n",
        "        line_out1 = line_out1.replace(\"[\",\"\").replace(\"]\",\"\").\\\n",
        "                                        replace(\"'\",\"\").replace(\" \",\"\")\n",
        "\n",
        "        # Open mvd_in\n",
        "        fo_mvd = open(mvd_in,\"r\")\n",
        "        csv_mvd = csv.reader(fo_mvd)\n",
        "\n",
        "        count_instances += 1\n",
        "\n",
        "        # Looping through csv_mvd\n",
        "        for line2 in csv_mvd:\n",
        "            if line1[2].strip() in str(line2):\n",
        "\n",
        "                # Clean line_out2\n",
        "                line_out2 = str(line2[i_SMILES+1:i_Complex])+\",\"\n",
        "                line_out2 += str(line2[i_Complex+1:i_Filename])+\",\"\n",
        "                line_out2 += str(line2[i_Filename+1:i_Ligand])+\",\"\n",
        "                line_out2 += str(line2[i_Ligand+1:i_Path])+\",\"\n",
        "                line_out2 += str(line2[i_Path+1:i_RMSD])+\",\"\n",
        "                line_out2 += str(line2[i_RMSD+1:i_S])+\",\"\n",
        "                line_out2 += str(line2[i_S+1:])\n",
        "                line_out2 = line_out2.\\\n",
        "                 replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\" \",\"\")\n",
        "                data_out += line_out1+\",\"+line_out2+\"\\n\"\n",
        "                fo_mvd.close()\n",
        "                break\n",
        "\n",
        "    # Close fo_san\n",
        "    fo_san.close()\n",
        "\n",
        "    # Open a new file and write data_out\n",
        "    fo_new = open(mvd_out,\"w\")\n",
        "    fo_new.write(data_out)\n",
        "\n",
        "    # Close fo_new\n",
        "    fo_new.close()\n",
        "\n",
        "    # Show message\n",
        "    msg_out = \"\\nNumber of instances written to file \"+mvd_out+\" : \"\n",
        "    msg_out += str(count_instances)\n",
        "    print(msg_out)\n",
        "\n",
        "################################################################################\n",
        "# Define main function                                                         #\n",
        "################################################################################\n",
        "def main():\n",
        "    ############################################################################\n",
        "    # Import section\n",
        "    ############################################################################\n",
        "    import sys\n",
        "    import csv\n",
        "    from urllib.request import urlretrieve\n",
        "\n",
        "    ############################################################################\n",
        "    # Define inputs\n",
        "    ############################################################################\n",
        "    #\n",
        "    ############################################################################\n",
        "    # CDK2 Ki\n",
        "    ############################################################################\n",
        "    # SAnDReS-related file\n",
        "    #san_in = \"./CDK2_Ki/cdk2_Ki_sandres.csv\"     # File with results obtained with SAnDReS\n",
        "    #san_url = \"https://bit.ly/cdk2_Ki_sandres\" # Url with san_in file\n",
        "    # MVD-related file\n",
        "    #mvd_in = \"./CDK2_Ki/cdk2_Ki_mvd.csv\"    \t   # File with results determined using MVD\n",
        "    #mvd_url = \"https://bit.ly/cdk2_Ki_mvd\"   # Url with mvd_in file\n",
        "    # PDB-related file\n",
        "    #pdb_in = \"./CDK2_Ki/CDK2_Ki_PDB_Test_Set.csv\"     # File with PDB codes for test set\n",
        "    #pdb_url = \"https://bit.ly/CDK2_Ki_PDB_Test_Set\" # Url with pdb_in file\n",
        "\n",
        "    ############################################################################\n",
        "    # CDK2-Cyclin A2\n",
        "    ############################################################################\n",
        "    # BindingDB\n",
        "    # https://www.bindingdb.org/rwd/jsp/dbsearch/PrimarySearch_ki.jsp?tag=comki&column=KI&complexid=97,50014798&energytern=kJ/mole&kiunit=nM&icunit=nM&submit=Search&target=Cyclin-A2%2FCyclin-dependent+kinase+2\n",
        "    # Cyclin-A2/Cyclin-dependent kinase 2 [ 164 ]\n",
        "    # BindingDB: 2024-02-15\n",
        "    # Binding: Ki\n",
        "    # Filter my 164 hits\n",
        "    # Targets 1▿\n",
        "    # Publications 14▿\n",
        "    # Institutions 8▿\n",
        "    # Affinity: 2.9 to 1.3E+4 nM▿\n",
        "    # Xtal structures: 6\n",
        "    # Docked structures: 4\n",
        "    # Catalog Cmpds: 12\n",
        "    #\n",
        "    # SAnDReS-related file\n",
        "    san_in = \"cdk2_cyclin_a_ki_sandres.csv\"\n",
        "    san_url = \"https://drive.usercontent.google.com/u/0/uc?id=16HyPn_8ZAvgtHFRCYICUGc_Dq-6BvpnM&export=download\"\n",
        "\n",
        "    # MVD-related file\n",
        "    mvd_in = \"cdk2_cyclin_a_ki_mvd.csv\"\n",
        "    mvd_url = \"https://drive.usercontent.google.com/u/0/uc?id=1toALRJ2o37jX1iM0YpGNsLoQvYVBYV6b&export=download\"\n",
        "\n",
        "    # PDB-related file\n",
        "    pdb_in = \"cdk2_cyclin_a_ki_pdb_test_set.csv\"\n",
        "    pdb_url = \"https://drive.usercontent.google.com/u/0/uc?id=1bi1oDCeZ7zLuZ5GqdepMBv_FG4hKHByi&export=download\"\n",
        "\n",
        "    ############################################################################\n",
        "    # CDK19 IC50\n",
        "    ############################################################################\n",
        "    #san_in = \"CDK19_IC50_SAN.csv\"     # File with results obtained with SAnDReS\n",
        "    #san_url = \"https://drive.usercontent.google.com/download?id=1FvUlSugUjcUNuR-1E71eXZ5dQRrHangK&export=view&authuser=0\" # Url with san_in\n",
        "                                                             # file\n",
        "    # MVD-related file\n",
        "    #mvd_in = \"CDK19_IC50_MVD.csv\"     # File with results determined using MVD\n",
        "    #mvd_url = \"https://drive.usercontent.google.com/download?id=1GaS9tCaB5VeRTa2eKwGdjNsYDmPpBgCh&export=view&authuser=0\"   # Url with\n",
        "                                                               # mvd_in file\n",
        "\n",
        "    # PDB-related file\n",
        "    #pdb_in = \"CDK19_IC50_PDB_Test_Set.csv\" # File with PDB codes for test set\n",
        "    #pdb_url = \"https://drive.usercontent.google.com/download?id=1Kpay9Da_hxgr5_GEy_bNkAWpbcxSEOwO&export=view&authuser=0\" # Url with pdb_in\n",
        "                                                             # file\n",
        "\n",
        "    ############################################################################\n",
        "    # Download files\n",
        "    ############################################################################\n",
        "    # Download san_in file\n",
        "    msg_out = \"\\n\\nDownloading \"+san_in\n",
        "    print(msg_out,end = \"...\")\n",
        "    urlretrieve(san_url, san_in)\n",
        "    san_in = \"/content/\"+san_in       # For Google Colab environment\n",
        "    print(\"done!\")\n",
        "\n",
        "    # Download mvd_in file\n",
        "    msg_out = \"Downloading \"+mvd_in\n",
        "    print(msg_out,end = \"...\")\n",
        "    urlretrieve(mvd_url, mvd_in)\n",
        "    mvd_in = \"/content/\"+mvd_in       # For Google Colab environment\n",
        "    print(\"done!\")\n",
        "\n",
        "    # Download pdb_in file\n",
        "    msg_out = \"Downloading \"+pdb_in\n",
        "    print(msg_out,end = \"...\")\n",
        "    urlretrieve(pdb_url, pdb_in)\n",
        "    pdb_in = \"/content/\"+pdb_in       # For Google Colab environment\n",
        "    print(\"done!\")\n",
        "\n",
        "    ############################################################################\n",
        "    # Split dataset\n",
        "    ############################################################################\n",
        "    # Set up an empty list for pdb access codes\n",
        "    pdb_lst = []\n",
        "\n",
        "    # Try to open a csv file\n",
        "    try:\n",
        "        fo_pdb = open(pdb_in,\"r\")\n",
        "        csv_pdb = csv.reader(fo_pdb)\n",
        "    except IOError:\n",
        "        msg_out = \"\\nIOError! I can't find file \"+pdb_in+\"!\"\n",
        "        sys.exit(msg_out)\n",
        "\n",
        "    # Looping through csv_pdb to get PDB codes\n",
        "    for pdbs in csv_pdb:\n",
        "        for pdb in pdbs:\n",
        "            pdb_lst.append(pdb)\n",
        "\n",
        "    # Close file\n",
        "    fo_pdb.close()\n",
        "\n",
        "    # Try to open a csv file\n",
        "    try:\n",
        "        fo_bind = open(san_in,\"r\")\n",
        "        csv_bind = csv.reader(fo_bind)\n",
        "    except IOError:\n",
        "        msg_out = \"\\nIOError! I can't find file \"+san_in+\"!\"\n",
        "        sys.exit(msg_out)\n",
        "\n",
        "    # Get header\n",
        "    for line in csv_bind:\n",
        "        training_out = \"\"\n",
        "\n",
        "        # Looping through column labels\n",
        "        for line1 in line:\n",
        "            training_out += line1.strip()+\",\"\n",
        "\n",
        "        training_out = training_out[:len(training_out)-1]+\"\\n\"\n",
        "        test_out = training_out\n",
        "        break\n",
        "\n",
        "    # Assign zero to count_train\n",
        "    count_train = 0\n",
        "\n",
        "    # Looping through csv_bind\n",
        "    for line in csv_bind:\n",
        "        if line[0].strip() in pdb_lst:\n",
        "            test_out += str(line).replace(\"[\",\"\").replace(\"]\",\"\").\\\n",
        "                        replace(\"'\",\"\").replace(\" \",\"\")+\"\\n\"\n",
        "        else:\n",
        "            training_out += str(line).replace(\"[\",\"\").replace(\"]\",\"\").\\\n",
        "                        replace(\"'\",\"\").replace(\" \",\"\")+\"\\n\"\n",
        "            count_train += 1\n",
        "\n",
        "    # Open new files\n",
        "    training_set_file = san_in.replace(\".csv\",\"_training_set.csv\")\n",
        "    test_set_file = san_in.replace(\".csv\",\"_test_set.csv\")\n",
        "    fo_training = open(training_set_file,\"w\")\n",
        "    fo_test = open(test_set_file,\"w\")\n",
        "\n",
        "    # Write data\n",
        "    fo_training.write(training_out)\n",
        "    fo_test.write(test_out)\n",
        "\n",
        "    # Close files\n",
        "    fo_bind.close()\n",
        "    fo_training.close()\n",
        "    fo_test.close()\n",
        "\n",
        "    # Show message\n",
        "    msg_out = \"\\nFile \"+training_set_file+\" has \"+str(count_train)+\" instances.\"\n",
        "    msg_out += \"\\nFile \"+test_set_file+\" has \"+str(len(pdb_lst))\n",
        "    msg_out += \" instances.\"\n",
        "    print(msg_out)\n",
        "\n",
        "    ############################################################################\n",
        "    # Merge datasets\n",
        "    ############################################################################\n",
        "    # Call merge_san_mvd() function for the training set\n",
        "    merge_san_mvd(training_set_file,mvd_in)\n",
        "\n",
        "    # Call merge() function for the test set\n",
        "    merge_san_mvd(test_set_file,mvd_in)\n",
        "\n",
        "################################################################################\n",
        "# Call main() function                                                         #\n",
        "################################################################################\n",
        "main()\n",
        "################################################################################"
      ]
    }
  ]
}