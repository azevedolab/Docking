{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **prepare_MVD: Prepare Data from Molegro Virtual Docker (MVD)**\n",
        "\n",
        "This Jupyter Notebook reads a CSV (comma-separated value) file with energy terms and ligand descriptors determined using Molegro Virtual Docker (MVD) ([Thomsen & Christensen, 2006](https://doi.org/10.1021/jm051197e); [Bitencourt-Ferreira & de Azevedo, 2019](https://doi.org/10.1007/978-1-4939-9752-7_10)) and adds binding affinity data. It needs two input CSV files: one with binding affinity information filtered from the BindingDB ([Liu et al., 2007](https://doi.org/10.1093/nar/gkl999); [Liu et al., 2025](https://doi.org/10.1093/nar/gkae1075)) with [prepare_BindingDB](https://colab.research.google.com/drive/1DNUjJED4zMskHoIgJGJuY-GdRsd7CYeM?usp=sharing) and another with ligand data generated with the program MVD (e.g., during a docking screen with ligands for which binding affinity data is available). All ligands in the CSV file generated with the program MVD should be in the input file obtained from BindingDB (filtered with [prepare_BindingDB](https://colab.research.google.com/drive/1DNUjJED4zMskHoIgJGJuY-GdRsd7CYeM?usp=sharing)). The code prepare_MVD will merge the two CSV files and output a CSV file with ligand information and binding affinity (e.g., pK<sub>i</sub>) for structures of the dataset. It also outputs randomized training and test sets. We may employ these files to build regression models using the Jupyter Notebook [SKReg4Model (Scikit-Learn Regressors for Modeling)](https://colab.research.google.com/drive/13khGiZAgJeexwNjNDi1fSluQfcRyBCDg) or the regression methods available in the Molegro Data Modeller (MDM) ([Thomsen & Christensen, 2006](https://doi.org/10.1021/jm051197e); [Bitencourt-Ferreira & de Azevedo, 2019](https://doi.org/10.1007/978-1-4939-9752-7_10)).\n",
        "<br> </br>\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=1KKq50wqwA3InD0ovx0EiG9CLM25BYSYq&export=view&authuser=0\" width=600 alt=\"prepare_MVD\">\n",
        "<br><i>Schematic flowchart for prepare_MVD. It adds binding affinity data to a CSV file generated with MVD ([Thomsen & Christensen, 2006](https://doi.org/10.1021/jm051197e); [Bitencourt-Ferreira & de Azevedo, 2019](https://doi.org/10.1007/978-1-4939-9752-7_10)).</i></br>\n",
        "<br></br>\n",
        "**References**\n",
        "<br></br>\n",
        "Bitencourt-Ferreira G, de Azevedo WF Jr. Molegro Virtual Docker for Docking. Methods Mol Biol. 2019;2053:149-167. PMID: 31452104. [DOI: 10.1007/978-1-4939-9752-7_10](https://doi.org/10.1007/978-1-4939-9752-7_10) [PubMed](https://pubmed.ncbi.nlm.nih.gov/31452104/)\n",
        "<br></br>\n",
        "De Azevedo WF Jr, Quiroga R, Villarreal MA, da Silveira NJF, Bitencourt-Ferreira G, da Silva AD, Veit-Acosta M, Oliveira PR, Tutone M, Biziukova N, Poroikov V, Tarasova O, Baud S. SAnDReS 2.0: Development of machine-learning models to explore the scoring function space. J Comput Chem. 2024; 45(27): 2333-2346. PMID: 38900052. [DOI: 10.1002/jcc.27449](https://doi.org/10.1002/jcc.27449) [PubMed](https://pubmed.ncbi.nlm.nih.gov/38900052/)\n",
        "<br></br>\n",
        "Liu T, Lin Y, Wen X, Jorissen RN, Gilson MK. BindingDB: a web-accessible database of experimentally determined protein-ligand binding affinities. Nucleic Acids Res. 2007; 35(Database issue): D198-201.  PMID: 17145705.\n",
        "[DOI: 10.1093/nar/gkl999](https://doi.org/10.1093/nar/gkl999)\n",
        "[PubMed](https://pubmed.ncbi.nlm.nih.gov/17145705/)\n",
        "<br></br>\n",
        "Liu T, Hwang L, Burley SK, Nitsche CI, Southan C, Walters WP, Gilson MK. BindingDB in 2024: a FAIR knowledgebase of protein-small molecule binding data. Nucleic Acids Res. 2025; 53(D1): D1633-D1644. PMID: 39574417.\n",
        "[DOI: 10.1093/nar/gkae1075](https://doi.org/10.1093/nar/gkae1075)\n",
        "[PubMed](https://pubmed.ncbi.nlm.nih.gov/39574417/)\n",
        "<br></br>\n",
        "Thomsen R, Christensen MH. MolDock: a new technique for high-accuracy molecular docking. J Med Chem. 2006; 49(11): 3315-21. [DOI: 10.1021/jm051197e](https://doi.org/10.1021/jm051197e) [PubMed](https://pubmed.ncbi.nlm.nih.gov/16722650/)\n",
        "<br></br>\n",
        "\n",
        "It follows the complete Python code."
      ],
      "metadata": {
        "id": "ncAHYrLhXDT1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1-1gD-UUrhJ",
        "outputId": "6e71ef26-6ddf-456a-e060-5c1d86caaa3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading CDK1_Rerank.csv...done!\n",
            "\n",
            "Downloading CDK1_4Binding.csv...done!\n",
            "\n",
            "\n",
            "Merging data...done!\n",
            "\n",
            "Number of instances written to file CDK1_Rerank_Binding_Affinity.csv : 138\n",
            "\n",
            "Training set ligands:\n",
            "50431339,50431338,50431335,50431337,50431360,50431363,50425011,81430,50443449,50425010,12617,12622,12619,50431349,50431336,50423754,50431359,50443451,50431351,50443453,50443450,50431352,50205472,12620,12612,50431356,50443457,50431354,50431347,50391210,50391213,50391212,50431358,50443458,50423758,50431353,8061,50431348,50391211,50568686,50443447,50391215,50567666,12618,50431341,50443444,12609,50113281,12616,50431345,50423762,50425002,50501588,50501587,12608,50443445,50443456,12610,50443443,50423753,50431342,50501599,81436,50423756,50567665,50391214,50443446,50567652,50423760,50423765,50568704,50423763,50570302,50567655,50391216,50570299,50570304,50501608,12604,50501605,50431362,12607,50568699,50110183,12613,50568703,12624,50568691,50563322,50501601,50501579,50501581,50525156,12615,50423757,50525155,50501612,50501590,50423768,50501611,50501603,50501610,50501591,50568698,50501578,50501584,50391218,12605,12606,50423769,50423764\n",
            "\n",
            "Test set ligands:\n",
            "12621,50431340,12623,50443455,50423755,50431350,12611,50391209,50443454,50431355,50568690,50443452,50443448,50431346,50423759,50431334,50391217,50501586,50423761,50568688,50431343,50431357,50423766,50501606,12614,50423767,50501593\n",
            "\n",
            "Test set file: /content/CDK1_Rerank_Binding_Affinity_Test_Set.csv\n",
            "Training set file: /content/CDK1_Rerank_Binding_Affinity_Training_Set.csv\n",
            "Number of structures in training set: 111\n",
            "Number of structures in test set: 27\n",
            "\n",
            "\n",
            "###########################################################\n",
            "#                         SUMMARY                         #\n",
            "###########################################################\n",
            "Source of binding affinty: CDK1_4Binding.csv\n",
            "Input CSV file: CDK1_Rerank.csv\n",
            "Output CSV file: CDK1_Rerank_Binding_Affinity.csv\n",
            "Type of binding affinity: Ki\n",
            "Number of ligands written to output CSV file: 138\n",
            "###########################################################\n",
            "#            MOLEGRO VIRTUAL DOCKER REFERENCES            #\n",
            "###########################################################\n",
            "# DOI:10.1021/jm051197e                                   #\n",
            "# DOI:10.1007/978-1-4939-9752-7_10                        #\n",
            "###########################################################\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "#\n",
        "################################################################################\n",
        "# Dr. Walter F. de Azevedo, Jr.                                                #\n",
        "# [Scopus](https://www.scopus.com/authid/detail.uri?authorId=7006435557)       #\n",
        "# [GitHub](https://github.com/azevedolab)                                      #\n",
        "# January 12, 2025                                                             #\n",
        "################################################################################\n",
        "#\n",
        "# Import section\n",
        "import csv, random, requests, sys, warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "################################################################################\n",
        "# Define MVD() class                                                           #\n",
        "################################################################################\n",
        "class MVD(object):\n",
        "    \"\"\"Class to create a CSV file with MVD docking results and BindingDB\n",
        "    affinity data.\n",
        "\n",
        "    It has the following attributes:\n",
        "    bind_csv_in (string):           Input CSV file\n",
        "    bind_csv_id (string):           Google drive identification for a CSV file\n",
        "    bind_in (string):               Type of binding affinty\n",
        "    mvd_in (string)                 Input CSV file with descritors and energy\n",
        "                                    terms determined with MVD\n",
        "    mvd_id (string):                Google drive identification for a CSV file\n",
        "    test_size_in (float):           Percentage of test set\n",
        "    seed_in (int):                  Random seed\n",
        "    mvd_out (string):               Output CSV file with MVD data and binding\n",
        "                                    affinity information\n",
        "        \"\"\"\n",
        "    # Define constructor method\n",
        "    def __init__(self,bind_csv_in,bind_csv_id,bind_in,mvd_in,mvd_id,\n",
        "                                                        test_size_in,seed_in):\n",
        "        \"\"\"Constructor method\"\"\"\n",
        "        # Define attributes\n",
        "        self.bind_csv_in = bind_csv_in\n",
        "        self.bind_csv_id = bind_csv_id\n",
        "        self.bind_in = bind_in\n",
        "        self.mvd_in = mvd_in\n",
        "        self.mvd_id = mvd_id\n",
        "        self.test_size_in = test_size_in\n",
        "        self.seed_in = seed_in\n",
        "\n",
        "        # Define empty lists and additional strings\n",
        "        self.lig_code_test = []\n",
        "        self.lig_code_train = []\n",
        "        self.mvd_out = self.mvd_in.replace(\".csv\",\"_Binding_Affinity.csv\")\n",
        "        self.drive_string1 = \"https://drive.usercontent.google.com/u/0/uc?id=\"\n",
        "        self.drive_string2 = \"&export=download\"\n",
        "\n",
        "    # Define read() method\n",
        "    def read(self):\n",
        "        \"\"\"Method to read a CSV file generated with MVD.\"\"\"\n",
        "        # Download CSV\n",
        "        msg_out = \"\\nDownloading \"+self.mvd_in\n",
        "        print(msg_out,end=\"...\")\n",
        "        mvd_url = self.drive_string1+self.mvd_id+self.drive_string2\n",
        "        mvd = requests.get(mvd_url, allow_redirects=True)\n",
        "        open(\"/content/\"+self.mvd_in, \"wb\").write(mvd.content)\n",
        "        print(\"done!\")\n",
        "\n",
        "        # Try to open mvd_in\n",
        "        try:\n",
        "            fo_mvd = open(\"/content/\"+self.mvd_in,\"r\")\n",
        "            csv_mvd = csv.reader(fo_mvd)\n",
        "        except IOError:\n",
        "            msg_out = \"\\nIOError! I can't find file \"+\"/content/\"+self.mvd_in\n",
        "            sys.exit(msg_out)\n",
        "\n",
        "        # Looping through csv_mvd\n",
        "        for line2 in csv_mvd:\n",
        "            i = 0\n",
        "            # Looping through line2\n",
        "            for aux in line2:\n",
        "                if aux.strip() == \"SMILES\":\n",
        "                    self.i_SMILES = i\n",
        "                elif aux.strip() == \"Complex\":\n",
        "                    self.i_Cpx = i\n",
        "                elif aux.strip() == \"Filename\":\n",
        "                    self.i_Filename = i\n",
        "                elif aux.strip() == \"Ligand\":\n",
        "                    self.i_Ligand = i\n",
        "                elif aux.strip() == \"Path\":\n",
        "                    self.i_Path = i\n",
        "                elif aux.strip() == \"RMSD\":\n",
        "                    self.i_RMSD = i\n",
        "                elif aux.strip() == \"SimilarityScore\":\n",
        "                    self.i_S = i\n",
        "\n",
        "                # Update i\n",
        "                i += 1\n",
        "\n",
        "            # Clean header2\n",
        "            # Warning!\n",
        "            # This code keeps the labels used in MVD except for\n",
        "            # \"E-Intra (tors, ligand atoms)\".\n",
        "            # We replaced it for \"E-Intra(tors-ligand atoms)\".\n",
        "            self.header2 = str(line2[self.i_SMILES+1:self.i_Cpx])+\",\"\n",
        "            self.header2 += str(line2[self.i_Cpx+1:self.i_Filename])+\",\"\n",
        "            self.header2 += str(line2[self.i_Filename+1:self.i_Ligand])+\",\"\n",
        "            self.header2 += str(line2[self.i_Ligand+1:self.i_Path])+\",\"\n",
        "            self.header2 += str(line2[self.i_Path+1:self.i_RMSD])+\",\"\n",
        "            self.header2 += str(line2[self.i_RMSD+1:self.i_S])+\",\"\n",
        "            self.header2 += str(line2[self.i_S+1:])\n",
        "            self.header2 = self.header2.replace(\"[\",\"\").replace(\" \",\"\").\\\n",
        "            replace(\"]\",\"\").replace(\"'\",\"\").\\\n",
        "            replace(\"Cofactor(VdW)\",\"Cofactor (VdW)\").\\\n",
        "            replace(\"Cofactor(elec)\",\"Cofactor (elec)\").\\\n",
        "            replace(\"Cofactor(hbond)\",\"Cofactor (hbond)\").\\\n",
        "            replace(\"E-Inter(cofactor-ligand)\",\"E-Inter (cofactor - ligand)\").\\\n",
        "            replace(\"E-Inter(protein-ligand)\",\"E-Inter (protein - ligand)\").\\\n",
        "            replace(\"E-Inter(water-ligand)\",\"E-Inter (water - ligand)\").\\\n",
        "            replace(\"E-Intertotal\",\"E-Inter total\").\\\n",
        "            replace(\"E-Intra(clash)\",\"E-Intra (clash)\").\\\n",
        "            replace(\"E-Intra(elec)\",\"E-Intra (elec)\").\\\n",
        "            replace(\"E-Intra(hbond)\",\"E-Intra (hbond)\").\\\n",
        "            replace(\"E-Intra(sp2-sp2)\",\"E-Intra (sp2-sp2)\").\\\n",
        "            replace(\"E-Intra(steric)\",\"E-Intra (steric)\").\\\n",
        "            replace(\"E-Intra(tors)\",\"E-Intra (tors)\").\\\n",
        "            replace(\"E-Intra(tors,ligandatoms)\",\"E-Intra (tors-ligand atoms)\").\\\n",
        "            replace(\"E-Intra(vdw)\",\"E-Intra (vdw)\").\\\n",
        "            replace(\"E-SoftConstraintPenalty\",\"E-Soft Constraint Penalty\").\\\n",
        "            replace(\"VdW(LJ12-6)\",\"VdW (LJ12-6)\")\n",
        "\n",
        "            break\n",
        "\n",
        "        # Close fo_mvd to re-open it into the next loop\n",
        "        fo_mvd.close()\n",
        "\n",
        "        # Download CSV\n",
        "        msg_out = \"\\nDownloading \"+self.bind_csv_in\n",
        "        print(msg_out,end=\"...\")\n",
        "        bind_url = self.drive_string1+self.bind_csv_id+self.drive_string2\n",
        "        bind = requests.get(bind_url, allow_redirects=True)\n",
        "        open(\"/content/\"+self.bind_csv_in, \"wb\").write(bind.content)\n",
        "        print(\"done!\")\n",
        "\n",
        "        # Read a CSV file (binding affinity)\n",
        "        self.affinity_data = pd.read_csv(\"/content/\"+self.bind_csv_in,\n",
        "                                                                delimiter=\",\")\n",
        "        self.exp_ligs = self.affinity_data.iloc[:,0]\n",
        "        self.exp_bind = self.affinity_data.iloc[:,1]\n",
        "\n",
        "    # Define merge() method\n",
        "    def merge(self):\n",
        "        \"\"\"Method to merge BindingDB and MVD data. It adds binding affinity data\n",
        "        to a MVD result file.\"\"\"\n",
        "        # Merge data\n",
        "        msg_out = \"\\n\\nMerging data\"\n",
        "        print(msg_out,end =  \"...\")\n",
        "\n",
        "        # New header\n",
        "        self.data_out = \"BindingDB Reactant_set_id,p\"\n",
        "        self.data_out += self.bind_in.replace(\" (nM)\",\",\")+self.header2+\"\\n\"\n",
        "\n",
        "        # Looping through self.exp_ligs\n",
        "        self.count_instances = 0\n",
        "        for i,lig in enumerate(self.exp_ligs):\n",
        "            # Open mvd_in\n",
        "            fo_mvd = open(\"/content/\"+self.mvd_in,\"r\")\n",
        "            csv_mvd = csv.reader(fo_mvd)\n",
        "\n",
        "            # Update self.count_instances\n",
        "            self.count_instances += 1\n",
        "\n",
        "            # Looping through csv_mvd\n",
        "            for line2 in csv_mvd:\n",
        "                if str(lig) in str(line2):\n",
        "                    # Clean line_out2\n",
        "                    line_out2 = str(line2[self.i_SMILES+1:self.i_Cpx])+\",\"\n",
        "                    line_out2 += str(line2[self.i_Cpx+1:self.i_Filename])+\",\"\n",
        "                    line_out2 += str(line2[self.i_Filename+1:self.i_Ligand])+\",\"\n",
        "                    line_out2 += str(line2[self.i_Ligand+1:self.i_Path])+\",\"\n",
        "                    line_out2 += str(line2[self.i_Path+1:self.i_RMSD])+\",\"\n",
        "                    line_out2 += str(line2[self.i_RMSD+1:self.i_S])+\",\"\n",
        "                    line_out2 += str(line2[self.i_S+1:])\n",
        "                    line_out2 = line_out2.replace(\"[\",\"\").replace(\"]\",\"\").\\\n",
        "                                                replace(\"'\",\"\").replace(\" \",\"\")\n",
        "\n",
        "                    # Set up line_out1 with binding affinity data\n",
        "                    line_out1 = str(lig)+\",\"\n",
        "                    line_out1 += str(-np.log10(float(self.exp_bind[i])*(1e-9)))\n",
        "\n",
        "                    # Add new line\n",
        "                    self.data_out += line_out1+\",\"+line_out2+\"\\n\"\n",
        "                    fo_mvd.close()\n",
        "                    break\n",
        "\n",
        "        print(\"done!\")\n",
        "\n",
        "    # Define write() method\n",
        "    def write(self):\n",
        "        \"\"\"Method to write merged BindingDB and MVD data.\"\"\"\n",
        "        # Open a new file and write self.data_out\n",
        "        fo_new = open(\"/content/\"+self.mvd_out,\"w\")\n",
        "        fo_new.write(self.data_out)\n",
        "\n",
        "        # Close fo_new\n",
        "        fo_new.close()\n",
        "\n",
        "        # Show message\n",
        "        msg_out = \"\\nNumber of instances written to file \"+self.mvd_out+\" : \"\n",
        "        msg_out += str(self.count_instances)\n",
        "        print(msg_out)\n",
        "\n",
        "    # Define randomize() method to automatically determine the structures\n",
        "    # for training and test sets\n",
        "    def randomize(self):\n",
        "        \"\"\"Method to generate the codes for training and test sets\"\"\"\n",
        "        # Try to open self.mvd_out\n",
        "        try:\n",
        "            file2open = \"/content/\"+self.mvd_out\n",
        "            data = np.genfromtxt(file2open,skip_header=1,delimiter=\",\")\n",
        "            rows = data[:,8]\n",
        "            n_rows = len(rows)\n",
        "            fo_data = open(file2open,\"r\")\n",
        "            csv_data = csv.reader(fo_data)\n",
        "\n",
        "            # Set up seed for pseudo-random number generator\n",
        "            random.seed(a=self.seed_in, version=2)\n",
        "\n",
        "            # Set up empty list\n",
        "            test_rows = []\n",
        "\n",
        "            # Assign zero to i\n",
        "            i = 0\n",
        "\n",
        "            # Get unique integers\n",
        "            while i < int(self.test_size_in*n_rows):\n",
        "                # Generate pseudo-random\n",
        "                n = random.randint(0,n_rows)\n",
        "\n",
        "                # Check if n is in the list\n",
        "                if n not in test_rows:\n",
        "\n",
        "                    # Append number\n",
        "                    test_rows.append(n)\n",
        "\n",
        "                    # Update i\n",
        "                    i += 1\n",
        "\n",
        "            # Assign zero to i\n",
        "            i_line = 0\n",
        "\n",
        "            # Looping through csv_data to jump first line\n",
        "            for line in csv_data:\n",
        "                break\n",
        "\n",
        "            # Looping through csv_data\n",
        "            for line in csv_data:\n",
        "                # Split\n",
        "                if i_line in test_rows:\n",
        "                    self.lig_code_test.append(line[0])\n",
        "                else:\n",
        "                    self.lig_code_train.append(line[0])\n",
        "\n",
        "                # Update\n",
        "                i_line += 1\n",
        "\n",
        "            # Close file (dataset)\n",
        "            fo_data.close()\n",
        "\n",
        "            # Get number of instances\n",
        "            count_test = len(self.lig_code_test)\n",
        "            count_train = len(self.lig_code_train)\n",
        "\n",
        "            # Show summary\n",
        "            summary = \"\\nTraining set ligands:\\n\"\n",
        "            summary += str(self.lig_code_train).replace(\"[\",\"\").replace(\"]\",\"\").\\\n",
        "                                            replace(\"'\",\"\").replace(\" \",\"\")\n",
        "            summary += \"\\n\\nTest set ligands:\\n\"\n",
        "            summary += str(self.lig_code_test).replace(\"[\",\"\").replace(\"]\",\"\").\\\n",
        "                                            replace(\"'\",\"\").replace(\" \",\"\")\n",
        "            print(summary)\n",
        "\n",
        "            # Invoke write_codes() method\n",
        "            self.write_codes()\n",
        "\n",
        "        # Handle IOError\n",
        "        except IOError:\n",
        "            msg_out = \"\\nI can't find \"+file2open+\" file!\"\n",
        "            print(msg_out)\n",
        "            return\n",
        "\n",
        "    # Define generate() method to split a dataset\n",
        "    def generate(self):\n",
        "        \"\"\"Method to split dataset in training and test sets\"\"\"\n",
        "        # Call read_codes() method\n",
        "        self.read_codes()\n",
        "\n",
        "        # Try to open self.mvd_out\n",
        "        try:\n",
        "            file2open = \"/content/\"+self.mvd_out\n",
        "            fo_data = open(file2open,\"r\")\n",
        "            csv_data = csv.reader(fo_data)\n",
        "\n",
        "            # Set up empty lists\n",
        "            test_set = []\n",
        "            training_set = []\n",
        "\n",
        "            # Looping through csv_data to get header\n",
        "            for line in csv_data:\n",
        "\n",
        "                # Some editing 1\n",
        "                line_out = str(line)\n",
        "                line_out = line_out.replace(\"[\",\"\").replace(\"]\",\"\").\\\n",
        "                        replace(\"'\",\"\").replace(\" ,\",\",\") .replace(\", \",\",\")\n",
        "                header = str(line_out)\n",
        "                break\n",
        "\n",
        "            # Looping through csv_data\n",
        "            for line in csv_data:\n",
        "\n",
        "                # Some editing 2\n",
        "                line_out = str(line)\n",
        "                line_out = line_out.replace(\"[\",\"\").replace(\"]\",\"\").\\\n",
        "                                            replace(\"'\",\"\").replace(\" \",\"\")\n",
        "\n",
        "                # Split\n",
        "                if line[0] in self.lig_code_test:\n",
        "                    test_set.append(line_out)\n",
        "                elif line[0] in self.lig_code_train:\n",
        "                    training_set.append(line_out)\n",
        "                else:\n",
        "                    print(\"\\nStructure \"+str(line[0])+\" not in the datasets!\")\n",
        "\n",
        "            # Close file (dataset)\n",
        "            fo_data.close()\n",
        "\n",
        "            # Open new file (training set)\n",
        "            file2create1 = \"/content/\"+self.mvd_out.replace(\".csv\",\"\")\n",
        "            file2create1 += \"_Training_Set.csv\"\n",
        "            f_train = open(file2create1,\"w\")\n",
        "\n",
        "            # Write header for training set\n",
        "            f_train.write(header+\"\\n\")\n",
        "\n",
        "            # Assign zero to count_train and count_test\n",
        "            count_train = 0\n",
        "            count_test = 0\n",
        "\n",
        "            # Looping through training set\n",
        "            for line in training_set:\n",
        "                f_train.write(line+\"\\n\")\n",
        "                count_train += 1\n",
        "\n",
        "            # Close file (training set)\n",
        "            f_train.close()\n",
        "\n",
        "            # Open new file (test set)\n",
        "            file2create2 = \"/content/\"+self.mvd_out.replace(\".csv\",\"\")\n",
        "            file2create2 += \"_Test_Set.csv\"\n",
        "            f_test = open(file2create2,\"w\")\n",
        "\n",
        "            # Write header for test set\n",
        "            f_test.write(header+\"\\n\")\n",
        "\n",
        "            # Looping through test set\n",
        "            for line in test_set:\n",
        "                f_test.write(line+\"\\n\")\n",
        "                count_test += 1\n",
        "\n",
        "            # Close file (test set)\n",
        "            f_test.close()\n",
        "\n",
        "            # Show summary\n",
        "            summary = \"\\nTest set file: \"+file2create2\n",
        "            summary += \"\\nTraining set file: \"+file2create1\n",
        "            summary+=\"\\nNumber of structures in training set: \"+str(count_train)\n",
        "            summary += \"\\nNumber of structures in test set: \"+str(count_test)\n",
        "            print(summary)\n",
        "\n",
        "        # Handle IOError\n",
        "        except IOError:\n",
        "            msg_out = \"\\nI can't find \"+file2open+\" file!\"\n",
        "            print(msg_out)\n",
        "            return\n",
        "\n",
        "    # Define read_codes() method\n",
        "    def read_codes(self):\n",
        "        \"\"\"Method to read codes in the codes_training_set.csv\n",
        "        and codes_test_set.csv files\"\"\"\n",
        "        # Try to open codes_training_set.csv and codes_test_set.csv\n",
        "        try:\n",
        "            file2open1 = \"/content/\"+\"codes_training_set.csv\"\n",
        "            fo_train = open(file2open1,\"r\")\n",
        "            csv_train = csv.reader(fo_train)\n",
        "            file2open2 = \"/content/\"+\"codes_test_set.csv\"\n",
        "            fo_test = open(file2open2,\"r\")\n",
        "            csv_test = csv.reader(fo_test)\n",
        "\n",
        "            # Looping through csv_train\n",
        "            lig_code = \"\"\n",
        "            for line1 in csv_train:\n",
        "\n",
        "                # Some editing\n",
        "                aux_line = str(line1).replace(\"'\",\"\").replace(\" \",\"\").\\\n",
        "                                                replace(\"[\",\"\").replace(\"]\",\"\")\n",
        "\n",
        "                # Get codes\n",
        "                for char1 in aux_line:\n",
        "                    if char1 != \",\":\n",
        "                        lig_code += char1\n",
        "                    else:\n",
        "                        self.lig_code_train.append(lig_code)\n",
        "                        lig_code = \"\"\n",
        "\n",
        "            # Add last code\n",
        "            self.lig_code_train.append(lig_code)\n",
        "\n",
        "            # Looping through csv_test\n",
        "            lig_code = \"\"\n",
        "            for line2 in csv_test:\n",
        "                # Some editing\n",
        "                aux_line = str(line2)\n",
        "                aux_line = aux_line.replace(\"'\",\"\").replace(\" \",\"\").\\\n",
        "                                                replace(\"[\",\"\").replace(\"]\",\"\")\n",
        "\n",
        "                # Get codes\n",
        "                for char2 in aux_line:\n",
        "                    if char2 != \",\":\n",
        "                        lig_code += char2\n",
        "                    else:\n",
        "                        self.lig_code_test.append(lig_code)\n",
        "                        lig_code = \"\"\n",
        "\n",
        "            # Add last code\n",
        "            self.lig_code_test.append(lig_code)\n",
        "\n",
        "            # Close files\n",
        "            fo_train.close()\n",
        "            fo_test.close()\n",
        "\n",
        "        # Handle IOError\n",
        "        except IOError:\n",
        "            print(\"\\nIOError! I can't find CSV file!\")\n",
        "\n",
        "    # Define write_codes()\n",
        "    def write_codes(self):\n",
        "        \"\"\"Method to write codes for structures in the training\n",
        "        and test sets\"\"\"\n",
        "        # Open new file for training set\n",
        "        file2create_training = \"/content/\"+\"codes_training_set.csv\"\n",
        "        fo_training = open(file2create_training,\"w\")\n",
        "\n",
        "        # Write codes for training set\n",
        "        # Write first code\n",
        "        fo_training.write(str(self.lig_code_train[0]))\n",
        "\n",
        "        # Looping through self.lig_code_train to write the remaining codes\n",
        "        for lig_code in self.lig_code_train[1:]:\n",
        "            fo_training.write(\",\"+str(lig_code))\n",
        "\n",
        "        # Close file\n",
        "        fo_training.close()\n",
        "\n",
        "        # Open new file for test set\n",
        "        file2create_test = \"/content/\"+\"codes_test_set.csv\"\n",
        "        fo_test = open(file2create_test,\"w\")\n",
        "\n",
        "        # Write codes for test set\n",
        "        # Write first code\n",
        "        fo_test.write(str(self.lig_code_test[0]))\n",
        "\n",
        "        # Looping through self.lig_code_test to write the remaining codes\n",
        "        for lig_code in self.lig_code_test[1:]:\n",
        "            fo_test.write(\",\"+str(lig_code))\n",
        "\n",
        "        # Close file\n",
        "        fo_test.close()\n",
        "\n",
        "    # Define summarize() method\n",
        "    def summarize(self):\n",
        "        \"\"\"Method to write a summary of the data.\"\"\"\n",
        "        # Show summary\n",
        "        summary = \"\\n\\n\"+59*\"#\"\n",
        "        summary += \"\\n\"+\"#\"+24*\" \"+\" SUMMARY \"+24*\" \"+\"#\"\n",
        "        summary += \"\\n\"+59*\"#\"\n",
        "        summary += \"\\nSource of binding affinty: \"+self.bind_csv_in\n",
        "        summary += \"\\nInput CSV file: \"+self.mvd_in\n",
        "        summary += \"\\nOutput CSV file: \"+self.mvd_out+\"\\n\"\n",
        "        summary += \"Type of binding affinity: \"\n",
        "        summary += self.bind_in.replace(\" (nM)\",\"\")+\"\\n\"\n",
        "        summary += \"Number of ligands written to output CSV file: \"\n",
        "        summary += str(self.count_instances)+\"\\n\"\n",
        "        summary += 59*\"#\"\n",
        "        summary += \"\\n\"+\"#\"+11*\" \"+\" MOLEGRO VIRTUAL DOCKER REFERENCES \"\n",
        "        summary += 11*\" \"+\"#\\n\"\n",
        "        summary += 59*\"#\"\n",
        "        summary += \"\\n# DOI:10.1021/jm051197e\"+35*\" \"+\"#\"\n",
        "        summary += \"\\n# DOI:10.1007/978-1-4939-9752-7_10\"+24*\" \"+\"#\"\n",
        "        summary += \"\\n\"+59*\"#\"\n",
        "        print(summary)\n",
        "\n",
        "################################################################################\n",
        "# Define main function                                                         #\n",
        "################################################################################\n",
        "def main():\n",
        "    # Define inputs for each dataset\n",
        "    ############################################################################\n",
        "    #  Cyclin-dependent kinase/G2/mitotic-specific cyclin- 1 [ 181 ]\n",
        "    ############################################################################\n",
        "    mvd_in = \"CDK1_Rerank.csv\"                      # CSV file\n",
        "    mvd_id = \"13_A_Q9kcCOzAHXXa7VVVbLJRI-nZ_Xvr\"    # Drive id for a CSV file\n",
        "    bind_csv_in = \"CDK1_4Binding.csv\"               # Binding-affinity file\n",
        "    bind_csv_id = \"1c79XnWg3psrM6gjqXT5hNaYUQP6t8e9C\" # Drive id for a CSV file\n",
        "    bind_in = \"Ki (nM)\"                             # Binding affinity\n",
        "    test_size_in = 0.2                              # Test set size\n",
        "    seed_in = 271828                                # Random seed\n",
        "\n",
        "    ############################################################################\n",
        "    # Cyclin-dependent kinase 2/G1/S-specific cyclin-E1 [ 1450 (2102) ]\n",
        "    ############################################################################\n",
        "    #mvd_in = \"CDK2_Rerank.csv\"                      # CSV file\n",
        "    #mvd_id = \"1ANT6bRACoEe1jaK19fvkNpZvVR-F8LYb\"    # Drive id for a CSV file\n",
        "    #bind_csv_in = \"CDK2_4Binding.csv\"               # Binding-affinity file\n",
        "    #bind_csv_id = \"1B3W-tShOAwH2SPe4oBWK0prIBSqxfYxG\"  # Drive id for a CSV file\n",
        "    #bind_in = \"Ki (nM)\"                             # Binding affinity\n",
        "    #test_size_in = 0.2                              # Test set size\n",
        "    #seed_in = 271828                                # Random seed\n",
        "\n",
        "    ############################################################################\n",
        "    # Cyclin-A2/Cyclin-dependent kinase 2 [ 164 ]\n",
        "    ############################################################################\n",
        "    #mvd_in = \"CDK2-CyclinA2_Ki_Plants.csv\"          # CSV file\n",
        "    #mvd_id = \"1gR_2LqjpkH6NcypeuntHKTENEky_r_t1\"    # Drive id for a CSV file\n",
        "    #bind_csv_in = \"CDK2-Cyclin_A2_Ki_4Binding.csv\"  # Binding-affinity file\n",
        "    #bind_csv_id = \"13URHyV6445rNcZ8peG5vEr04w_yj7ouu\"  # Drive id for a CSV file\n",
        "    #bind_in = \"Ki (nM)\"                             # Binding affinity\n",
        "    #test_size_in = 0.2                              # Test set size\n",
        "    #seed_in = 271828                                # Random seed\n",
        "\n",
        "    ############################################################################\n",
        "    # Cyclin-dependent kinase 4/G1/S-specific cyclin-D1 [ 455 (460) ]\n",
        "    ############################################################################\n",
        "    #mvd_in = \"CDK4_Plants.csv\"                      # CSV file\n",
        "    #mvd_id = \"1RwJo8TtbZhtmAmKFghGapr1fZMvymd8W\"    # Drive id for a CSV file\n",
        "    #bind_csv_in = \"CDK4_4Binding.csv\"               # Binding-affinity file\n",
        "    #bind_csv_id = \"1aZcr8q6k_VwjJHfL9u4z0QOt9CMR6nBm\" # Drive id for a CSV file\n",
        "    #bind_in = \"Ki (nM)\"                             # Binding affinity\n",
        "    #test_size_in = 0.2                              # Test set size\n",
        "    #seed_in = 271828                                # Random seed\n",
        "\n",
        "    ############################################################################\n",
        "    # Cyclin-dependent kinase 6/G1/S-specific cyclin-D1 [ 415 ]\n",
        "    ############################################################################\n",
        "    #mvd_in = \"CDK6_Plants.csv\"                      # CSV file\n",
        "    #mvd_id = \"1sG9191oaOMdZi5rG4wAIl07r-163mk72\"    # Drive id for a CSV file\n",
        "    #bind_csv_in = \"CDK6_4Binding.csv\"               # Binding-affinity file\n",
        "    #bind_csv_id = \"1rjOX6Xsxw62Umskd7Um2zWQgmh620abG\" # Drive id for a CSV file\n",
        "    #bind_in = \"Ki (nM)\"                             # Binding affinity\n",
        "    #test_size_in = 0.2                              # Test set size\n",
        "    #seed_in = 271828                                # Random seed\n",
        "\n",
        "    ############################################################################\n",
        "    # Cyclin-H/Cyclin-dependent kinase 7 [ 123 ]\n",
        "    ############################################################################\n",
        "    #mvd_in = \"CDK7_Rerank.csv\"                      # CSV file\n",
        "    #mvd_id = \"1AjUC7BMwdLwVxIHRFFAT2kc8ofgIyYOY\"    # Drive id for a CSV file\n",
        "    #bind_csv_in = \"CDK7_4Binding.csv\"               # Binding-affinity file\n",
        "    #bind_csv_id = \"1rO7q9ng5ThTWEr4OmgDNMKrtQSZ6EnlH\" # Drive id for a CSV file\n",
        "    #bind_in = \"Ki (nM)\"                             # Binding affinity\n",
        "    #test_size_in = 0.2                              # Test set size\n",
        "    #seed_in = 271828                                # Random seed\n",
        "\n",
        "    ############################################################################\n",
        "    # Cyclin-T1/Cyclin-dependent kinase 9 [ 201 ]\n",
        "    ############################################################################\n",
        "    #mvd_in = \"CDK9_Plants.csv\"                      # CSV file\n",
        "    #mvd_id = \"1-kHTh0WxjVAmH_uy9ZmW5jg5sKQKENHU\"    # Drive id for a CSV file\n",
        "    #bind_csv_in = \"CDK9_4Binding.csv\"               # Binding-affinity file\n",
        "    #bind_csv_id = \"1VYLgHza5DAG8jztHsWxQHRtMobvjmahE\" # Drive id for a CSV file\n",
        "    #bind_in = \"Ki (nM)\"                             # Binding affinity\n",
        "    #test_size_in = 0.2                              # Test set size\n",
        "    #seed_in = 271828                                # Random seed\n",
        "\n",
        "    ############################################################################\n",
        "    # Cyclin-C/Cyclin-dependent kinase 19 [ 123 (124) ]\n",
        "    ############################################################################\n",
        "    #mvd_in = \"CDK19_Rerank.csv\"                     # CSV file\n",
        "    #mvd_id = \"1rg4fCLwGS2qHhdRE6dMmDMT9zJoAZmzk\"    # Drive id for a CSV file\n",
        "    #bind_csv_in = \"CDK19_4Binding.csv\"              # Binding-affinity file\n",
        "    #bind_csv_id = \"1l-ztSkgoTa4Jv5LLEoErqvKhTC7WWQeI\" # Drive id for a CSV file\n",
        "    #bind_in = \"IC50 (nM)\"                           # Binding affinity\n",
        "    #test_size_in = 0.2                              # Test set size\n",
        "    #seed_in = 271828                                # Random seed\n",
        "\n",
        "    # Instantiate an object of MVD() class\n",
        "    m1 = MVD(bind_csv_in,bind_csv_id,bind_in,mvd_in,mvd_id,test_size_in,seed_in)\n",
        "\n",
        "    # Invoke read() method\n",
        "    m1.read()\n",
        "\n",
        "    # Invoke merge() method\n",
        "    m1.merge()\n",
        "\n",
        "    # Invoke write() method\n",
        "    m1.write()\n",
        "\n",
        "    # Invoke randomize() method\n",
        "    m1.randomize()\n",
        "\n",
        "    # Invoke generate() method\n",
        "    m1.generate()\n",
        "\n",
        "    # Invoke summarize() method\n",
        "    m1.summarize()\n",
        "\n",
        "################################################################################\n",
        "# Call main() function                                                         #\n",
        "################################################################################\n",
        "main()\n",
        "################################################################################"
      ]
    }
  ]
}