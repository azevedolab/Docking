{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Multiple Lasso Regression Models for the CASF-2016 K<sub>i</sub> Dataset**\n",
        "\n",
        "This Jupyter Notebook builds multiple regression models using the Lasso (Least Absolute Shrinkage and Selection Operator) ([Géron, 2023](https://www.isbns.net/isbn/9781098125974/)) method for data from the CASF-2016 K<sub>i</sub> dataset ([de Azevedo et al., 2024](https://doi.org/10.1002/jcc.27449)). This code employs the [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) class from the [Scikit-Learn](https://scikit-learn.org/stable/) library ([Pedregosa et al., 2011](https://doi.org/10.48550/arXiv.1201.0490)) to generate multiple regression models obtained from the combination of features. It evaluates the regression model's predictive performance using metrics recommended by [Walsh et al., 2021](https://doi.org/10.1038/s41592-021-01205-4) and de [Azevedo et al., 2024](https://doi.org/10.1002/jcc.27449).\n",
        "<br></br>\n",
        "<img src=\"https://drive.usercontent.google.com/download?id=12XlpAMdW1RAWOSF6mHiBos4RdiTX1xtj&export=view&authuser=0\" width=800 alt=\"PDB: 2A4L\">\n",
        "<br><i>Structure of a protein-ligand complex ([de Azevedo et al., 1997](https://doi.org/10.1111/j.1432-1033.1997.0518a.x)) with an inhibitor bound to the macromolecule (PDB access code: [2A4L](https://www.rcsb.org/structure/2A4L)).</i></br>\n",
        "<br></br>\n",
        "**References**\n",
        "\n",
        "de Azevedo WF Jr, Quiroga R, Villarreal MA, da Silveira NJF,\n",
        "Bitencourt-Ferreira G, da Silva AD, Veit-Acosta M, Oliveira PR, Tutone M, Biziukova N, Poroikov V, Tarasova O, Baud S. SAnDReS 2.0: Development of machine-learning models to explore the scoring function space. J Comput Chem. 2024; 45(27): 2333-2346.\n",
        "PMID: 38900052. [DOI: 10.1002/jcc.27449](https://doi.org/10.1002/jcc.27449) [PubMed](https://pubmed.ncbi.nlm.nih.gov/38900052/)\n",
        "<br></br>\n",
        "Géron, A. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow 3e: Concepts, Tools, and Techniques to Build Intelligent Systems, 3rd ed.; O’Reilly Media: Sebastopol, CA, 2023.\n",
        "[ISBN: 978-1-098-12597-4](https://www.isbns.net/isbn/9781098125974/)\n",
        "<br></br>\n",
        "Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel M, Prettenhofer P, Weiss R, Dubourg V, Verplas J, Passos A, Cournapeau D, Brucher M, Perrot M, Duchesnay E. Scikitlearn: Machine Learning in Python. J Mach Learn Res., 2011; 12:2825–2830. [DOI: 10.48550/arXiv.1201.0490](https://doi.org/10.48550/arXiv.1201.0490)\n",
        "<br></br>\n",
        "Walsh I, Fishman D, Garcia-Gasulla D, Titma T, Pollastri G; ELIXIR Machine Learning Focus Group; Harrow J, Psomopoulos FE, Tosatto SCE. DOME: recommendations for supervised machine learning validation in biology. Nat Methods. 2021; 18(10): 1122-1127. [DOI: 10.1038/s41592-021-01205-4](https://doi.org/10.1038/s41592-021-01205-4) [PubMed](https://pubmed.ncbi.nlm.nih.gov/34316068/)\n",
        "<br></br>\n",
        "\n",
        "It follows the complete Python code.\n"
      ],
      "metadata": {
        "id": "gyD2AznZZFeG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4c-rPpNY_AN",
        "outputId": "254ffab6-ec04-4b46-8819-274e37ce2842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading and preprocessing file: CASF-2016_Ki_training.csv...done!\n",
            "\n",
            "Downloading and preprocessing file: CASF-2016_Ki_test.csv...done!\n",
            "\n",
            "Generating regression models...done!\n",
            "\n",
            "Number of generated regression models:  6435\n",
            "\n",
            "Metrics saved to file: regression_metrics.csv\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "#\n",
        "################################################################################\n",
        "# Dr. Walter F. de Azevedo, Jr.                                                #\n",
        "# [Scopus](https://www.scopus.com/authid/detail.uri?authorId=7006435557)       #\n",
        "# [GitHub](https://github.com/azevedolab)                                      #\n",
        "# July 20, 2024                                                                #\n",
        "################################################################################\n",
        "#\n",
        "################################################################################\n",
        "# Import section                                                               #\n",
        "################################################################################\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "################################################################################\n",
        "# Define cross_validation() function                                           #\n",
        "################################################################################\n",
        "# Function to set up k-fold class. Kfold class to build a n fold\n",
        "# cross-validation loop and test the generalization ability of regression. With\n",
        "# cross-validation, we generally obtain a more conservative estimate(that is,\n",
        "# the error is larger). The cross-validation estimate is a better estimate of\n",
        "# how well we could generalize to predict on unseen data.\n",
        "#\n",
        "################################################################################\n",
        "# Reference                                                                    #\n",
        "################################################################################\n",
        "# Coelho LP, Richert W. (2015) Building Machine Learning Systems with\n",
        "# Python. 2nd ed. Packt Publishing Ltd. Birmingham UK. 301 pp. See page 162\n",
        "# (Cross-validation for regression)\n",
        "def cross_validation(model,X,y,n_splits,random_state,verbose):\n",
        "\n",
        "    # Import section\n",
        "    from sklearn.model_selection import KFold, cross_val_score\n",
        "    from warnings import simplefilter\n",
        "    import numpy as np\n",
        "\n",
        "    # Set up k-fold class\n",
        "    kf = KFold(n_splits=n_splits,shuffle=True, random_state=random_state)\n",
        "\n",
        "    # Ignore all future warnings\n",
        "    simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "    # Looping through kf.split()\n",
        "    for train,test in kf.split(X):\n",
        "\n",
        "        # Generate regression model\n",
        "        model.fit(X[train],y[train])\n",
        "\n",
        "    # Show Walsh metrics if requestes\n",
        "    if verbose:\n",
        "        # Show average coefficient of determination using n-fold crossvalidation\n",
        "        scores = cross_val_score(model,X,y,cv=kf)\n",
        "        msg_out = \"Average coefficient of determination using n-fold \"\n",
        "        msg_out += \"cross-validation\"\n",
        "        print(\"\\n\"+msg_out+\":\",np.mean(scores))\n",
        "\n",
        "    # Return model\n",
        "    return model\n",
        "\n",
        "################################################################################\n",
        "# Define Walsh_and_de_Azevedo_regression_metrics() function                    #\n",
        "################################################################################\n",
        "def Walsh_and_de_Azevedo_regression_metrics(y,y_pred):\n",
        "    \"\"\"Function to calculate regression metrics as recommended by\n",
        "    [Walsh et 2021](https://pubmed.ncbi.nlm.nih.gov/34316068/)\n",
        "    and\n",
        "    [de Azevedo Jr et al., 2024](https://pubmed.ncbi.nlm.nih.gov/38900052/))\n",
        "\n",
        "    Parameters:\n",
        "    y: array with experimental data (dimensions: (n,) )\n",
        "    y_pred: array with predicted values (dimensions: (n,) )\n",
        "\n",
        "    where n is the number of instances\n",
        "    \"\"\"\n",
        "\n",
        "    # Import section for this function\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "    from scipy import stats\n",
        "    import numpy as np\n",
        "\n",
        "    # Determine metrics\n",
        "    n = len(y)\n",
        "    y_bar = y.mean()\n",
        "    rss = np.sum( np.square(y_pred - y) )\n",
        "    rmse =  np.sqrt( (np.sum( (y - y_pred)**2 ))/n )\n",
        "    ss_res = np.sum( (y - y_pred)**2 )\n",
        "    ss_tot = np.sum( (y - y_bar)**2 )\n",
        "    R2 = 1 - ss_res/ss_tot\n",
        "    mae = median_absolute_error(y,y_pred)\n",
        "    r_pearson,p_pearson = stats.pearsonr(y,y_pred)\n",
        "    rho,p_spearman = stats.spearmanr(y,y_pred)\n",
        "    core_dome = rmse**2 + mae**2 + (R2 -1)**2\n",
        "    dome =    np.sqrt( core_dome )\n",
        "    edomer2 = np.sqrt( core_dome + (r_pearson**2 - 1)**2 )\n",
        "    edomerho =np.sqrt( core_dome + (rho**2 - 1)**2 )\n",
        "    edome =   np.sqrt( core_dome + (r_pearson**2 - 1)**2 + (rho**2 - 1)**2 )\n",
        "\n",
        "    # Return metrics\n",
        "    return r_pearson,p_pearson,rho,p_spearman,rss,rmse,mae,R2,dome,edomer2,\\\n",
        "    edomerho,edome\n",
        "\n",
        "################################################################################\n",
        "# Training set                                                                 #\n",
        "################################################################################\n",
        "file_in = \"CASF-2016_Ki_training.csv\"            # Update here for a new dataset\n",
        "print(\"\\nDownloading and preprocessing file: \"+file_in,end=\"...\")\n",
        "url = \"https://bit.ly/CASF-2016_Ki_training\"     # Update here for a new dataset\n",
        "#feature_list =[\"Gauss 2\",\"C\",\"Q\",\"Torsions\",\"O\"] # Update here for a new dataset\n",
        "training_set_data = pd.read_csv(url,delimiter=\",\")\n",
        "y_train = training_set_data.iloc[:,8]            # Update here for a new dataset\n",
        "print(\"done!\")\n",
        "\n",
        "################################################################################\n",
        "# Test set                                                                     #\n",
        "################################################################################\n",
        "file_in = \"CASF-2016_Ki_test.csv\"                # Update here for a new dataset\n",
        "print(\"\\nDownloading and preprocessing file: \"+file_in,end=\"...\")\n",
        "url = \"https://bit.ly/CASF-2016_Ki_test\"         # Update here for a new dataset\n",
        "test_set_data = pd.read_csv(url,delimiter=\",\")\n",
        "y_test = test_set_data.iloc[:,8]                 # Update here for a new dataset\n",
        "print(\"done!\")\n",
        "\n",
        "################################################################################\n",
        "# Define additional inputs                                                     #\n",
        "################################################################################\n",
        "plt_scatter_X_label_str,plt_scatter_y_label_str = \"pK$_i$ (Experimental)\",\\\n",
        "                        \"pK$_i$ (Predicted)\"            # Define labels for axes\n",
        "plt_dpi = 1500                                          # Plot dpi\n",
        "\n",
        "################################################################################\n",
        "# Build regression models with Lasso                                           #\n",
        "################################################################################\n",
        "# Set up initial values\n",
        "n_models = 0\n",
        "rmse_list = []\n",
        "l = 8\n",
        "y_list = [y_train,y_test]\n",
        "data_list = [\"Training Set\",\"Test Set\"]\n",
        "lst_in = [\"Gauss 1\",\"Gauss 2\",\"Repulsion\",\"Hydrophobic\",\"Hydrogen\",\"Torsional\",\n",
        "\"Torsions\",\"Q\",\"Average Q\",\"C\",\"N\",\"O\",\"Ligand B-factor(A2)\",\n",
        "\"Receptor B-factor(A2)\",\"B-factor ratio (Ligand/Receptor)\"]\n",
        "data_out = \"Features,Data,n,r,p-value(r),r2,rho,p-value(rho),RSS,RMSE,MAE,R2,\"\n",
        "data_out += \"DOME,EDOMEr2,EDOMErho,EDOME\\n\"\n",
        "\n",
        "# Get all combinations of elements in lst_in and length l\n",
        "comb_lst_in = combinations(lst_in, l)\n",
        "\n",
        "# Show message\n",
        "msg_out = \"\\nGenerating regression models\"\n",
        "print(msg_out,end=\"...\")\n",
        "\n",
        "# Looping through comb_lst_in\n",
        "for feature_list in list(comb_lst_in):\n",
        "\n",
        "  # Make it a list\n",
        "  feature_list = list(feature_list)\n",
        "\n",
        "  try:\n",
        "    # For training set\n",
        "    X_train = training_set_data[feature_list]\n",
        "    scaler_train = preprocessing.StandardScaler().fit(X_train)\n",
        "    X_train = scaler_train.transform(X_train)\n",
        "\n",
        "    # For test set\n",
        "    X_test = test_set_data[feature_list]\n",
        "    scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
        "    X_test = scaler_test.transform(X_test)\n",
        "    n_models += 1\n",
        "\n",
        "    # Instantiate an object of Lasso() class\n",
        "    lin_reg = Lasso(\n",
        "        alpha = 0.04,\n",
        "        copy_X = True,\n",
        "        fit_intercept = True,\n",
        "        max_iter = 100,\n",
        "        positive = False,\n",
        "        precompute = False,\n",
        "        random_state = 42,\n",
        "        selection = \"cyclic\",\n",
        "        tol = 0.5,\n",
        "        warm_start = False\n",
        "    ).fit(X_train, y_train)\n",
        "\n",
        "    # Call cross_validation() function\n",
        "    lin_reg = cross_validation(lin_reg,X_train,y_train,5,46,False)\n",
        "    y_train_pred_reg = lin_reg.predict(X_train)\n",
        "    y_test_pred_reg = lin_reg.predict(X_test)\n",
        "    y_pred_list = [y_train_pred_reg,y_test_pred_reg]\n",
        "\n",
        "    # Looping through data\n",
        "    for count,y in enumerate(y_list):\n",
        "      # Call Walsh_and_de_Azevedo_regression_metrics() function\n",
        "      r_pearson,p_pearson,rho,p_spearman,rss,rmse,mae,R2,dome,edomer2,\\\n",
        "      edomerho,edome = \\\n",
        "      Walsh_and_de_Azevedo_regression_metrics(y_list[count],\n",
        "                                                            y_pred_list[count])\n",
        "\n",
        "      # Set up output line\n",
        "      line_out = str(feature_list).replace(\"'\",\"\").replace(\"[\",\"\").\\\n",
        "                                                replace(\"]\",\"\").replace(\",\",\" \")\n",
        "      line_out += \",\"+data_list[count]+\",\"+str(len(y))+\",\"\n",
        "      line_out += \"{:.4f}\".format(r_pearson)+\",\"+\"{:.4e}\".format(p_pearson)+\",\"\n",
        "      line_out += \"{:.4f}\".format(r_pearson**2)+\",\"+\"{:.4f}\".format(rho)+\",\"\n",
        "      line_out += \"{:.4e}\".format(p_spearman)+\",\"+\"{:.4e}\".format(rss)+\",\"\n",
        "      line_out += \"{:.4f}\".format(rmse)+\",\"+\"{:.4f}\".format(mae)+\",\"\n",
        "      line_out += \"{:.4f}\".format(R2)+\",\"+\"{:.4f}\".format(dome)+\",\"\n",
        "      line_out += \"{:.4f}\".format(edomer2)+\",\"+\"{:.4f}\".format(edomerho)+\",\"\n",
        "      line_out += \"{:.4f}\".format(edome)\n",
        "\n",
        "      # Update data_out\n",
        "      data_out += line_out+\"\\n\"\n",
        "\n",
        "  except:\n",
        "    print(\"\\nError I didn't generate a regression model for \",feature_list)\n",
        "\n",
        "print(\"done!\")\n",
        "\n",
        "# Open a new file and write data_out\n",
        "fo_out = open(\"regression_metrics.csv\",\"w\")\n",
        "fo_out.write(data_out)\n",
        "fo_out.close()\n",
        "print(\"\\nNumber of generated regression models: \",n_models)\n",
        "print(\"\\nMetrics saved to file: regression_metrics.csv\")\n",
        "################################################################################"
      ]
    }
  ]
}